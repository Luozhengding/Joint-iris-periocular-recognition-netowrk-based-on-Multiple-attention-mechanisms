{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2nyqtzw4CfO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable,Function\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from scipy.spatial.distance import pdist\n",
    "import cv2\n",
    "from img_enhance import enh_contrast\n",
    "import math\n",
    "\n",
    "# 不显示warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "use_gpu = torch.cuda.is_available() # 检测是否可以使用GPU, use_gpu的值为True则可以使用GPU\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使重复实验时结果不变\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNum = len(os.listdir('Periocular_Class/'))\n",
    "print('classNum:%s'%classNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于训练的网络\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MyNet_Eye(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=classNum, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(MyNet_Eye, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.centers = torch.zeros(classNum, 512).type(torch.FloatTensor)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = torch.cat((x, x, x), 1)  # torch.Size([69, 3, 224, 224])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        self.features = torch.flatten(x, 1)\n",
    "        return self.features\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于训练的网络\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MyNet_Iris(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=classNum, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(MyNet_Iris, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.centers = torch.zeros(classNum, 512).type(torch.FloatTensor)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        x = torch.cat((x, x, x), 1)  # torch.Size([69, 3, 224, 224])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        self.features = torch.flatten(x, 1)\n",
    "        return self.features\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris-Periocular-Attention-Feature-Fusion\n",
    "class AttentionFusionNet(nn.Module): # 数据格式是(batch_size, channel, height, weight)\n",
    "    def __init__(self):\n",
    "        super(AttentionFusionNet, self).__init__()\n",
    "        self.model_eye = model_eye\n",
    "        self.model_iris = model_iris\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1024, 1024, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.fc2 = nn.Linear(1024, classNum, bias=False)\n",
    "        self.centers = torch.zeros(classNum, 1024).type(torch.FloatTensor)\n",
    "            \n",
    "    def forward(self, eye_image, iris_image):\n",
    "        eye_feat = self.model_eye(eye_image)\n",
    "        iris_feat = self.model_iris(iris_image)\n",
    "        self.features = torch.cat((eye_feat, iris_feat), dim=-1)  # torch.Size([69, 1, 1024])\n",
    "        weightfeatures = self.features*self.fc1(self.features)\n",
    "        self.features = self.gamma*weightfeatures + self.features\n",
    "        self.features = torch.flatten(self.features, 1)  # torch.Size([69, 1024])\n",
    "        y = self.fc2(self.features)\n",
    "        return y, self.features\n",
    "    \n",
    "    def get_center_loss(self, target, alpha):\n",
    "        batch_size = target.size(0)\n",
    "        features_dim = self.features.size(1)\n",
    "        target_expand = target.view(batch_size,1).expand(batch_size,features_dim)\n",
    "\n",
    "        centers_var = Variable(self.centers)\n",
    "        centers_batch = centers_var.gather(0,target_expand).cuda()\n",
    "        criterion = nn.MSELoss()\n",
    "        center_loss = criterion(self.features,  centers_batch)\n",
    "\n",
    "        diff = centers_batch - self.features\n",
    "        unique_label, unique_reverse, unique_count = np.unique(target.cpu().data.numpy(), return_inverse=True, return_counts=True)\n",
    "        appear_times = torch.from_numpy(unique_count).gather(0,torch.from_numpy(unique_reverse))\n",
    "        appear_times_expand = appear_times.view(-1,1).expand(batch_size,features_dim).type(torch.FloatTensor)\n",
    "        diff_cpu = diff.cpu().data / appear_times_expand.add(1e-6)\n",
    "        diff_cpu = alpha * diff_cpu\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            self.centers[target.data[i]] -= diff_cpu[i].type(self.centers.type())\n",
    "        return center_loss, self.centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集和测试集\n",
    "transformer_IrisImage = transforms.Compose([transforms.Resize(224),transforms.CenterCrop(224),transforms.ToTensor()])\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, filenames, labels, transform):\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_iris = cv2.imread(self.filenames[idx], 0)\n",
    "        image_iris = cv2.resize(image_iris, (512, 64))\n",
    "        image_iris = enh_contrast(image_iris).astype(np.float32) / 255\n",
    "        image_iris = torch.unsqueeze(torch.from_numpy(image_iris), 0).to(torch.float32)  # torch.Size([1, 64, 512])\n",
    "        \n",
    "        eye_filename = self.filenames[idx].replace('NormalizedIris_Class','Periocular_Class')\n",
    "        eye_filename = eye_filename.replace('_imno.bmp','.tiff')\n",
    "        image_eye = Image.open(eye_filename)\n",
    "        image_eye = self.transform(image_eye)  # torch.Size([1, 224, 224])\n",
    "        return image_eye, image_iris, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = []\n",
    "data_dir = 'NormalizedIris_Class'\n",
    "ratio = [0.6, 0.2, 0.2]\n",
    "dataset = ImageFolder(data_dir)\n",
    "\n",
    "character = [[] for i in range(len(dataset.classes))]\n",
    "for x, y in dataset.samples:\n",
    "    character[y].append(x)\n",
    "    character[y].sort()\n",
    "    character[y].reverse()\n",
    "\n",
    "train_inputs, val_inputs, test_inputs = [], [], []\n",
    "train_labels, val_labels, test_labels = [], [], []\n",
    "for i, data in enumerate(character):\n",
    "    num_sample_train = int(len(data) * ratio[0])\n",
    "    num_sample_val = int(len(data) * ratio[1])\n",
    "    num_val_index = num_sample_train + num_sample_val\n",
    "\n",
    "    for x in data[:num_sample_train]:\n",
    "        train_inputs.append(str(x))\n",
    "        train_labels.append(i)\n",
    "    for x in data[num_sample_train:num_val_index]:\n",
    "        val_inputs.append(str(x))\n",
    "        val_labels.append(i)\n",
    "    for x in data[num_val_index:]:\n",
    "        test_inputs.append(str(x))\n",
    "        a = str(x).split('/')\n",
    "        test_filenames.append(a[2].replace('_imno.bmp','.mat'))\n",
    "        test_labels.append(i)\n",
    "\n",
    "train_data = MyDataset(train_inputs, train_labels, transformer_IrisImage)\n",
    "train_dataloader = DataLoader(train_data, batch_size=89, shuffle=True)\n",
    "val_data = MyDataset(val_inputs, val_labels, transformer_IrisImage)\n",
    "val_dataloader = DataLoader(val_data, batch_size=89, shuffle=False)\n",
    "test_data = MyDataset(test_inputs, test_labels, transformer_IrisImage)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "loader = {}\n",
    "loader['train'] = train_dataloader\n",
    "loader['val'] = val_dataloader\n",
    "loader['test'] = test_dataloader\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络对test的预测准确率\n",
    "model = AttentionFusionNet()\n",
    "model.load_state_dict(torch.load('models/ND_Eye_Iris_Recognition_Resnet18.pkl'))\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader['test']:\n",
    "        image_eye, image_iris, labels = data\n",
    "        image_eye, image_iris, labels = image_eye.cuda(), image_iris.cuda(), labels.cuda()\n",
    "        outs, fused_feature = model(image_eye, image_iris)\n",
    "        predictions = torch.argmax(outs, 1)\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] == labels[i]:\n",
    "                correct += 1\n",
    "    print('test_accuracy: %.3f'%(correct/len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试网络得到特征feat\n",
    "model = AttentionFusionNet()\n",
    "model.load_state_dict(torch.load('models/ND_Eye_Iris_Recognition_Resnet18.pkl'))\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader['test']:\n",
    "        image_eye, image_iris, labels = data\n",
    "        image_eye, image_iris, labels = image_eye.cuda(), image_iris.cuda(), labels.cuda()\n",
    "        outs, fused_feature = model(image_eye, image_iris)\n",
    "        fused_feature = fused_feature.cpu().detach().numpy()\n",
    "        savemat('test/%s'%test_filenames[i],{'fused_feature':fused_feature})\n",
    "        print('%d test/%s'%(i, test_filenames[i]))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较不同特征之间的欧式距离\n",
    "filenames = os.listdir('test/')\n",
    "filenames.sort()\n",
    "for i in range(len(filenames)):\n",
    "    print(i,filenames[i])\n",
    "    feat1 = loadmat('test/%s'%filenames[i])['fused_feature']\n",
    "    hd1 = []\n",
    "    hd2 = []\n",
    "    for j in range(len(filenames)):\n",
    "        feat2 = loadmat('test/%s'%filenames[j])['fused_feature']\n",
    "        dist = np.sqrt(np.sum(np.square(np.subtract(feat1, feat2))))\n",
    "        if filenames[i][0:6] == filenames[j][0:6]:\n",
    "            hd1.append(dist)\n",
    "        else:\n",
    "            hd2.append(dist)\n",
    "    savemat('CASIAV3_test_same/%s'%filenames[i],{'hd1':hd1})\n",
    "    savemat('CASIAV3_test_diff/%s'%filenames[i],{'hd2':hd2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max-min normalization\n",
    "filenames = os.listdir('CASIAV3_test_same/')\n",
    "filenames.sort()\n",
    "feats1=[]\n",
    "feats2=[]\n",
    "for i in range(len(filenames)):\n",
    "    intra_class = loadmat('CASIAV3_test_same/%s'%filenames[i])['hd1']\n",
    "    inter_class = loadmat('CASIAV3_test_diff/%s'%filenames[i])['hd2']\n",
    "    total = np.hstack((intra_class, inter_class))\n",
    "    intra_class = (intra_class - np.min(total)) / (np.max(total) - np.min(total))\n",
    "    inter_class = (inter_class - np.min(total)) / (np.max(total) - np.min(total))\n",
    "    for dd in intra_class:\n",
    "        for j in dd:\n",
    "            feats1.append(j)\n",
    "    for dd in inter_class:\n",
    "        for j in dd:\n",
    "            feats2.append(j)\n",
    "savemat('CASIAV3_test_same.mat',{'feats1':feats1})\n",
    "savemat('CASIAV3_test_diff.mat',{'feats2':feats2})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Attention_FaceIrisNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
